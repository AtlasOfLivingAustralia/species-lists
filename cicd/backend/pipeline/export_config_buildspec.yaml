version: 0.2
###
# This build project exports any variables needed for later stages and actions,
# builds the template configs used to launch the CloudFormation templates

env:
  shell: bash
  git-credential-helper: yes
  variables:
    DEBIAN_FRONTEND: noninteractive
#  secrets-manager:
#    DB_PASSWORD: $LISTS_SECRET_NAME:db-password
#    CAS_CLIENT_SECRET: $LISTS_SECRET_NAME:cas-client-secret
#    CAS_S2S_SECRET: $LISTS_SECRET_NAME:cas-s2s-client-secret
  exported-variables:
    - ACCESS_LOGS_S3_BUCKET_NAME
    - ADMIN_USER
    - ALA_SECRETS_NAME
    - APP_CERTIFICATE
    - CODEBUILD_BUILD_NUMBER
    - DATABASE_STACK_NAME
    - DOCKER_USERNAME
    - ECR_REPO
    - ECR_STACK_NAME
    - ECR_STACK_FILE_PFIX
    - EKS_NAMESPACE
    - HELM_RELEASE_NAME
    - HOSTED_ZONE
    - IMAGE_NAME
    - IMAGE_TAG
    - PRODUCT_COMPONENT
    - PRODUCT_NAME
    - SLACK_ALERT_CHANNEL
    - SLACK_DEPLOY_NOTIFICATION
    - UI_SUB_DOMAIN
    - WAF_STACK_FILE_PFIX
    - WAF_STACK_NAME
    - WS_SUB_DOMAIN

phases:

  install:
    commands:
      - echo Running on $(lsb_release -d | cut -f2)
      - echo aws-cli version $(aws --version)
      - pip install jinja2
      - export CUR_PIPELINE_FINGERPRINT=$(md5sum cicd/$PRODUCT_COMPONENT/pipeline/pipeline.yaml | awk '{print $1}')
      - # This next bit checks if the running pipeline is out of sync with the pipeline in the
      - # current code revision. If it is it re-launches itself! For a normal branch commit the
      - # pipeline is set to autorun on update so it will restart automatically and launch the
      - # latest revision on the branch. For a rollback we dont want it to restart automatically as
      - # we need to run a specific commit, not the latest. In this case the pipeline is set NOT to
      - # autorun on update. It will have to be manually started after the rollback pipeline
      - # has finished launching
      - | 
          if [[ $PIPELINE_FINGERPRINT != $CUR_PIPELINE_FINGERPRINT ]]; then
            echo existing pipeline is out of sync with current code revision, relaunching!
            cd cicd/$PRODUCT_COMPONENT/pipeline/
            ./deploy_pipeline.sh -e ${ENVIRONMENT:0:4} -b $SRC_BRANCH
            # pipeline execution should now stop if this is a rollback, 
            # or restart automatically if this a normal branch deploy
            exit 1
          else
            echo existing pipeline is in sync with current code revision, proceeding with the deploy!
          fi
    finally:
      - #echo This always runs even if the update or install command fails

  pre_build:
    commands:
      - echo Entered the pre_build phase...
      - echo source branch is $SRC_BRANCH
      - echo clean branch is $CLEAN_BRANCH
      - echo Environment is $ENVIRONMENT
      - echo generating environment vars...
      - cicd/gen_env_vars.py --env $ENVIRONMENT --clean-branch $CLEAN_BRANCH --conf cicd/$PRODUCT_COMPONENT/config.ini > env.txt
      - echo loading config..
      - set -a ; source env.txt ; set +a
      # this is not being used in the deploy build spec. The environment vars are exported into the pipeline namespace.
      - echo creating the app environment for the lists deployment...
      - |
         source cicd/unset_codebuild_env_vars.sh
         for var in $(printenv | awk -F= '{print $1}'); do
           echo "$var=\"$(printenv $var)\"" >> app.env
         done
    finally:
      - #echo This always runs

  build:
    commands:
      - echo Entered the build phase...
      # package templates and generate the template configs
      - |
          for i in cicd/$PRODUCT_COMPONENT/app/*.yaml; do
            stack=$(echo $i | sed 's/.yaml$//')
            aws cloudformation package --template-file $stack.yaml \
                                       --s3-bucket $ARTIFACTS_BUCKET \
                                       --s3-prefix $PRODUCT_NAME/$PRODUCT_COMPONENT/$CLEAN_BRANCH-$CODEBUILD_BUILD_NUMBER \
                                       --output-template-file ${stack}.yaml \
                                       --region $REGION

            echo Generating the template config for $stack
            cicd/gen_template_config.py --template ${stack}_template_config.j2 > ${stack}_template_config.json
          done
      - echo importing stack output
      - UPLOADS_S3_BUCKET_NAME=$(aws cloudformation describe-stacks --stack-name $BASE_STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='ListsUploadsBucket'].OutputValue" --output text)
      - DB_PASSWORD=$(aws secretsmanager get-secret-value --secret-id "$LISTS_SECRET_NAME" --query 'SecretString' --output text | jq -r '.["db-password"]')
      - DB_ENDPOINT=$(aws cloudformation describe-stacks --stack-name $DATABASE_STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='DocDbClusterEndpoint'].OutputValue" --output text)
      - DB_USERNAME=$(aws cloudformation describe-stacks --stack-name $DATABASE_STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='DocDbUsername'].OutputValue" --output text)
      - |
        USER_POOL_ID=$(aws cloudformation describe-stacks --stack-name $COGNITO_STACK_NAME \
          --query "Stacks[0].Outputs[?OutputKey=='UserPoolId'].OutputValue" --output text)
      - |
        CLIENT_ID=$(aws cloudformation describe-stacks --stack-name $BASE_STACK_NAME \
          --query "Stacks[0].Outputs[?OutputKey=='AppClientId'].OutputValue" --output text)
      - |
        CLIENT_SECRET=$(aws cognito-idp describe-user-pool-client --user-pool-id $USER_POOL_ID \
          --client-id $CLIENT_ID --query "UserPoolClient.ClientSecret" --output text)
      - |
        SERVER_TO_SERVER_CLIENT_ID=$(aws cloudformation describe-stacks --stack-name $BASE_STACK_NAME \
          --query "Stacks[0].Outputs[?OutputKey=='ServiceAppClientId'].OutputValue" --output text)
      - |
        SERVER_TO_SERVER_CLIENT_SECRET=$(aws cognito-idp describe-user-pool-client --user-pool-id $USER_POOL_ID \
          --client-id $SERVER_TO_SERVER_CLIENT_ID --query "UserPoolClient.ClientSecret" --output text)
      - OIDC_DISCOVERY_URI="https://cognito-idp.${AWS_REGION}.amazonaws.com/${USER_POOL_ID}/.well-known/openid-configuration"
#      - if environment is production or staging override the client id and secret with the cas values
      - |
        if [[ "$ENVIRONMENT" == "production" || "$ENVIRONMENT" == "staging" ]]; then
          CLIENT_ID=${CAS_CLIENT_ID}
          CLIENT_SECRET=${CAS_CLIENT_SECRET}
          SERVER_TO_SERVER_CLIENT_ID=${CAS_S2S_CLIENT_ID}
          SERVER_TO_SERVER_CLIENT_SECRET=${CAS_S2S_SECRET}
        fi
      - |
        if [ "$ELASTICSEARCH_AUTH_ENABLED" = "true" ]; then
          export ELASTICSEARCH_PASSWORD=$(aws secretsmanager get-secret-value --secret-id "$ELASTICSEARCH_SECRET_NAME" --query 'SecretString' --output text | jq -r '.["password"]')
        fi
      - ACCESS_LOGS_S3_BUCKET_NAME=$(aws cloudformation describe-stacks --stack-name $BASE_STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='LoadBalancerAccessLogsBucket'].OutputValue" --output text)
      - echo generating values file for helm...
      - | 
        echo "config:
          app:
            name: $APP_NAME
            url: $APP_URL
          graphql:
            enabled: $GRAPHQL_ENABLED
            path: $GRAPHQL_PATH
          release:
            directory: $RELEASE_DIRECTORY
            s3:
              enabled: $RELEASE_S3_ENABLED
              bucket: $RELEASE_S3_BUCKET
          multipart:
            maxFileSize: $MULTIPART_MAX_FILE_SIZE
            maxRequestSize: $MULTIPART_MAX_REQUEST_SIZE
          mongodb:
            username: $DB_USERNAME
            password: $DB_PASSWORD
            host: $DB_ENDPOINT
            port: $MONGODB_PORT
            autoIndexCreation: $MONGODB_AUTO_INDEX_CREATION
          namematching:
            baseUrl: $NAMEMATCHING_BASE_URL
          bie:
            baseUrl: $BIE_BASE_URL
            url: $BIE_URL
            imagesUrl: $BIE_IMAGES_URL
          biocache:
            baseUrl: $BIOCACHE_BASE_URL
          collectory:
            baseUrl: $COLLECTORY_BASE_URL
          images:
            baseUrl: $IMAGES_BASE_URL
            url: $IMAGE_URL
          userdetails:
            baseUrl: $USERDETAILS_BASE_URL
          security:
            jwt:
              userIdClaim: $SECURITY_JWT_USER_ID_CLAIM
              roleClaims: $SECURITY_JWT_ROLE_CLAIMS
              requireUserInfo: $SECURITY_JWT_REQUIRE_USER_INFO
              userProfileFromAccessToken: $SECURITY_JWT_USER_PROFILE_FROM_ACCESS_TOKEN
              rolesFromAccessToken: $SECURITY_JWT_ROLES_FROM_ACCESS_TOKEN
              enabled: $SECURITY_JWT_ENABLED
              discoveryUri: $OIDC_DISCOVERY_URI
              clientId: $CLIENT_ID
            apikey:
              enabled: $SECURITY_JWT_APIKEY_ENABLED
            admin:
              role: $SECURITY_ADMIN_ROLES
            m2m:
              scope: $SECURITY_M2M_SCOPE
          webservice:
            read:
              timeout: $WEBSERVICE_READ_TIMEOUT
            connect:
              timeout: $WEBSERVICE_CONNECT_TIMEOUT
            jwt: $WEBSERVICE_JWT
            jwtScopes: $WEBSERVICE_JWT_SCOPES
            clientId: $SERVER_TO_SERVER_CLIENT_ID
            clientSecret: $SERVER_TO_SERVER_CLIENT_SECRET
          migrate:
            url: $MIGRATE_URL
          oidc:
            enabled: $OIDC_ENABLED
            clientId: $CLIENT_ID
            discoveryUri: $OIDC_DISCOVERY_URI
          aws:
            s3:
              enabled: $S3_ENABLED
              tempBucket: $UPLOADS_S3_BUCKET_NAME
              region: $AWS_REGION
          temp:
            dir: $TEMP_DIR
        ingress:
          accessLogsPrefix: "logs"
          accessLogsBucket: "${ACCESS_LOGS_S3_BUCKET_NAME}"
        tags:
          product: "${PRODUCT_NAME}"
          component: "${PRODUCT_COMPONENT}"
          environment: "${ENVIRONMENT}"
          branch: "${CLEAN_BRANCH}"
          version: "${COMMIT_ID}"
          Name: "${HELM_RELEASE_NAME}"
        resources:
          requests:
            cpu: "${CPU_REQUEST}"      
            memory: "${MEMORY_REQUEST}" 
          limits:
            cpu: "${CPU_LIMIT}"      
            memory: "${MEMORY_LIMIT}"
        elasticsearch:
          deployment:
            name: $ELASTIC_HOST
          service:
            name: $ELASTIC_HOST
            host: $ELASTICSEARCH_ENDPOINT
            port: $ELASTIC_PORT
            username: $ELASTICSEARCH_USERNAME
            password: $ELASTICSEARCH_PASSWORD
            authEnabled: $ELASTICSEARCH_AUTH_ENABLED
            tlsEnabled: $ELASTICSEARCH_TLS_ENABLED
          single_node_es: $SINGLE_NODE_ES" > helm-values.yaml
    finally:
      - #echo This always runs


  post_build:
    commands:
      - #echo Entered the post_build phase...

artifacts:
  files:
    - '**/*'